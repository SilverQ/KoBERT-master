{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from transformers import AdamW, BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2573691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model_path = 'ksic_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5bef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "??BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def14324",
   "metadata": {},
   "source": [
    "#### 모델 저장의 방법\n",
    "* Pytorch는 모델을 저장할 때 torch.save(object, file) 함수 사용\n",
    "    * object : 모델 객체, file : 파일 이름\n",
    "##### 예시1\n",
    "* torch.save(model, 'model.pt')\n",
    "* model = torch.load('model.pt')\n",
    "##### 예시2\n",
    "* torch.save(model.state_dict(), 'model.pt')\n",
    "* model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d2f238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_v1.zip\n",
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(bertmodel, 'model_save_test/ksic_bert_model.pt')\n",
    "# model = torch.load('model_save_test/ksic_bert_model.pt')\n",
    "# # 이건 왜 성공하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55dc9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(),\n",
    "                              attention_mask=attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47698e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "model = torch.load(os.path.join(model_path, 'KSIC_KoBERT.pt'))\n",
    "# Can't get attribute 'BERTClassifier' on <module '__main__'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feb6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9296227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        max_vals, max_indices = torch.max(out, 1)\n",
    "#         test_eval=[]\n",
    "#         for i in out:\n",
    "#             logits=i\n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "#             min_v = min(logits)\n",
    "#             total = 0\n",
    "#             probability = []\n",
    "#             logits = np.round(new_softmax(logits), 3).tolist()\n",
    "#             for logit in logits:\n",
    "#                 print(logit)\n",
    "#                 probability.append(np.round(logit, 3))\n",
    "\n",
    "#             if np.argmax(logits) == 0:  emotion = \"기쁨\"\n",
    "#             elif np.argmax(logits) == 1: emotion = \"불안\"\n",
    "#             elif np.argmax(logits) == 2: emotion = '당황'\n",
    "#             elif np.argmax(logits) == 3: emotion = '슬픔'\n",
    "#             elif np.argmax(logits) == 4: emotion = '분노'\n",
    "#             elif np.argmax(logits) == 5: emotion = '상처'\n",
    "\n",
    "#             probability.append(emotion)\n",
    "#             print(probability)\n",
    "    return max_vals, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b61d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "??torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cfd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in tqdm(dataset)]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in tqdm(dataset)]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff80a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:35PM KST on Jun 26, 2022\n",
      "Completed to load BERTDataset\n"
     ]
    }
   ],
   "source": [
    "with open(\".cache/ksic_data_test_id.pickle\", \"rb\") as fr:\n",
    "    data_test_id = pickle.load(fr)\n",
    "with open('.cache/label_ksic.pickle', 'rb') as f:\n",
    "    ksic_index_dict = pickle.load(f)\n",
    "with open('.cache/ksic_label.pickle', 'rb') as f:\n",
    "    ksic_label_dict = pickle.load(f)\n",
    "print(time.strftime('%l:%M%p %Z on %b %d, %Y'))  # ' 1:36PM EDT on Oct 18, 2010'\n",
    "print('Completed to load BERTDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c56b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "batch_size = 8\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 10000\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bae493",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(data_test_id, batch_size=batch_size, num_workers=8\n",
    "#                                               , shuffle=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5281d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdh/PycharmProjects/KoBERT-master/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(620082, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38706e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X, y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a488de70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/77511 [00:00<1:24:25, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:36PM KST on Jun 26, 2022 batch_id:  0 , test acc 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6004/77511 [05:16<1:02:59, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:41PM KST on Jun 26, 2022 batch_id:  6000 , test acc 0.7739960006665556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12004/77511 [10:33<57:45, 18.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:46PM KST on Jun 26, 2022 batch_id:  12000 , test acc 0.7734355470377469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 18004/77511 [15:50<52:41, 18.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:51PM KST on Jun 26, 2022 batch_id:  18000 , test acc 0.7729640019998889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 24004/77511 [21:09<47:21, 18.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8:57PM KST on Jun 26, 2022 batch_id:  24000 , test acc 0.773368817965918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 30004/77511 [26:27<42:02, 18.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:02PM KST on Jun 26, 2022 batch_id:  30000 , test acc 0.7729492350254992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 36004/77511 [31:45<36:39, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:07PM KST on Jun 26, 2022 batch_id:  36000 , test acc 0.7736833699063915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 42004/77511 [37:04<31:27, 18.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:13PM KST on Jun 26, 2022 batch_id:  42000 , test acc 0.7740024047046499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 48004/77511 [42:22<26:09, 18.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:18PM KST on Jun 26, 2022 batch_id:  48000 , test acc 0.7739187725255724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 54004/77511 [47:40<20:48, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:23PM KST on Jun 26, 2022 batch_id:  54000 , test acc 0.7739671487565045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 60004/77511 [52:59<15:28, 18.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:29PM KST on Jun 26, 2022 batch_id:  60000 , test acc 0.7742475125414576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 66004/77511 [58:17<10:11, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:34PM KST on Jun 26, 2022 batch_id:  66000 , test acc 0.774692807684732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 72004/77511 [1:03:36<04:52, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:39PM KST on Jun 26, 2022 batch_id:  72000 , test acc 0.7748538214747017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77511/77511 [1:08:28<00:00, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 8min 1s, sys: 20.9 s, total: 1h 8min 22s\n",
      "Wall time: 1h 8min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_acc = 0.0\n",
    "results = []\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length\n",
    "    label = label.long().to(device)\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "    max_vals, max_indices = torch.max(out, 1)\n",
    "#     results.extend([out.tolist(), max_vals.tolist(), max_indices.tolist()])\n",
    "    results.append([out.tolist(), max_vals.tolist(), max_indices.tolist()])\n",
    "    test_acc += calc_accuracy(out, label)\n",
    "    if batch_id % 6000 == 0:\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y'), 'batch_id: ', batch_id, ', test acc {}'.format(test_acc / (batch_id+1)), )\n",
    "#     print(results[-3:])\n",
    "#     print('label: ', label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a422438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.cache/test_result_rework_20220626.pickle', \"wb\") as fw:\n",
    "    pickle.dump(results, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.cache/test_result.pickle', \"rb\") as fw:\n",
    "    result = pickle.load(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0131cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_np = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d998ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test_id.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_id.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6934c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoBERT",
   "language": "python",
   "name": "kobert-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
