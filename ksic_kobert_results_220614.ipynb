{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7292a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from transformers import AdamW, BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2573691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model_path = 'ksic_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea5bef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "??BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def14324",
   "metadata": {},
   "source": [
    "#### 모델 저장의 방법\n",
    "* Pytorch는 모델을 저장할 때 torch.save(object, file) 함수 사용\n",
    "    * object : 모델 객체, file : 파일 이름\n",
    "##### 예시1\n",
    "* torch.save(model, 'model.pt')\n",
    "* model = torch.load('model.pt')\n",
    "##### 예시2\n",
    "* torch.save(model.state_dict(), 'model.pt')\n",
    "* model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d2f238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_v1.zip\n",
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a3cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(bertmodel, 'model_save_test/ksic_bert_model.pt')\n",
    "# model = torch.load('model_save_test/ksic_bert_model.pt')\n",
    "# # 이건 왜 성공하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55dc9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(),\n",
    "                              attention_mask=attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47698e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "model = torch.load(os.path.join(model_path, 'KSIC_KoBERT.pt'))\n",
    "# Can't get attribute 'BERTClassifier' on <module '__main__'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8feb6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/hdh/PycharmProjects/KoBERT-master/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9296227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 모델 설정\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        max_vals, max_indices = torch.max(out, 1)\n",
    "#         test_eval=[]\n",
    "#         for i in out:\n",
    "#             logits=i\n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "#             min_v = min(logits)\n",
    "#             total = 0\n",
    "#             probability = []\n",
    "#             logits = np.round(new_softmax(logits), 3).tolist()\n",
    "#             for logit in logits:\n",
    "#                 print(logit)\n",
    "#                 probability.append(np.round(logit, 3))\n",
    "\n",
    "#             if np.argmax(logits) == 0:  emotion = \"기쁨\"\n",
    "#             elif np.argmax(logits) == 1: emotion = \"불안\"\n",
    "#             elif np.argmax(logits) == 2: emotion = '당황'\n",
    "#             elif np.argmax(logits) == 3: emotion = '슬픔'\n",
    "#             elif np.argmax(logits) == 4: emotion = '분노'\n",
    "#             elif np.argmax(logits) == 5: emotion = '상처'\n",
    "\n",
    "#             probability.append(emotion)\n",
    "#             print(probability)\n",
    "    return max_vals, max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54b61d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "??torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54cfd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in tqdm(dataset)]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in tqdm(dataset)]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ff80a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:41AM KST on Jun 20, 2022\n",
      "Completed to load BERTDataset\n"
     ]
    }
   ],
   "source": [
    "with open(\".cache/ksic_data_test_id.pickle\", \"rb\") as fr:\n",
    "    data_test_id = pickle.load(fr)\n",
    "with open('.cache/label_ksic.pickle', 'rb') as f:\n",
    "    ksic_index_dict = pickle.load(f)\n",
    "with open('.cache/ksic_label.pickle', 'rb') as f:\n",
    "    ksic_label_dict = pickle.load(f)\n",
    "print(time.strftime('%l:%M%p %Z on %b %d, %Y'))  # ' 1:36PM EDT on Oct 18, 2010'\n",
    "print('Completed to load BERTDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c56b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "batch_size = 16\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 10000\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0bae493",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(data_test_id, batch_size=batch_size, num_workers=8\n",
    "#                                               , shuffle=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5281d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hdh/PycharmProjects/KoBERT-master/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2007: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(620082, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38706e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X, y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a488de70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/38756 [00:00<1:11:56,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9:53AM KST on Jun 20, 2022 batch_id:  0 , test acc 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6003/38756 [09:41<53:08, 10.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:03AM KST on Jun 20, 2022 batch_id:  6000 , test acc 0.773444009331778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 12003/38756 [19:25<43:25, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:13AM KST on Jun 20, 2022 batch_id:  12000 , test acc 0.7733678443463045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 18003/38756 [29:08<33:40, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:22AM KST on Jun 20, 2022 batch_id:  18000 , test acc 0.7736861841008833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 24003/38756 [38:53<23:57, 10.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:32AM KST on Jun 20, 2022 batch_id:  24000 , test acc 0.7739182742385734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 30003/38756 [48:37<14:12, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:42AM KST on Jun 20, 2022 batch_id:  30000 , test acc 0.774247108429719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 36003/38756 [58:20<04:28, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:51AM KST on Jun 20, 2022 batch_id:  36000 , test acc 0.774851740229438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38756/38756 [1:02:48<00:00, 10.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "results = []\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length\n",
    "    label = label.long().to(device)\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "    max_vals, max_indices = torch.max(out, 1)\n",
    "    results.extend([out.tolist(), max_vals.tolist(), max_indices.tolist()])\n",
    "    test_acc += calc_accuracy(out, label)\n",
    "    if batch_id % 6000 == 0:\n",
    "        print(time.strftime('%l:%M%p %Z on %b %d, %Y'), 'batch_id: ', batch_id, ', test acc {}'.format(test_acc / (batch_id+1)), )\n",
    "#     print(results[-3:])\n",
    "#     print('label: ', label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a422438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.cache/test_result.pickle', \"wb\") as fw:\n",
    "    pickle.dump(results, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a0792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoBERT",
   "language": "python",
   "name": "kobert-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
